\documentclass{exam}
\usepackage{amsmath, amsfonts}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[super]{nth}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}


%\input{../macros}
%\renewcommand{\hide}[1]{#1}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill}

\pagestyle{headandfoot}

%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%
\newcommand{\duedate}{19.11.2021 (16:00)}
\newcommand{\due}{{\bf This assignment is due on \duedate.} }
\firstpageheader
{Due: \duedate}
{{\bf\lecture}\\ \assignment{1}}
{\lectors\\ \semester}

\runningheader
{Due: \duedate}
{\assignment{1}}
{\semester}
%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%

\firstpagefooter
{}
{\thepage}
{}

\runningfooter
{}
{\thepage}
{}

\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}

\section*{Exercise: Q-Learning (Tabular and Value Function Approximation)}

Link to github classroom: \url{https://classroom.github.com/a/ZtU6Nv_I}

\noindent
Complete the exercises regarding Q-Learning and record your observations. How do the hyperparameters change the outcome of your experiments?

\begin{questions}
	\titledquestion{Tabular Q-Learning}
	Implement the Q-Learning update step in \emph{q\_learning\_tabular.py} and try different state discretizations (\texttt{BINS}) and learning rates (\texttt{LEARNING\_RATE}).
	How does the number of states and learning rate affect the training of the RL algorithm?
	\titledquestion{Q-Learning with Linear Value Function Approximation}
	Implement Q-Learning with Linear Value Function Approximation.
	First create \emph{make\_Q} that takes an environment as input and creates a PyTorch Model.
	Then implement the value function training step in \emph{q\_learning\_vfa.py} using the \texttt{Q} module and the \texttt{optimizer}.
	How does the training differ from the tabular case?
	How sensitive is the algorithm to the weight initialization?

	Update the hyperparameters and the model to achieve a mean reward of more than 50 for the CartPole environment.
\end{questions}

For the open questions, please write your answers in `answers.txt`. We will grade those manually.

\end{document}